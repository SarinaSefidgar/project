{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bioelectra.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "preds = np.concatenate(ret[0]);\n",
        "real = np.concatenate(ret[1]);\n",
        "\n",
        "print('test predictions: {}'.format(preds));\n",
        "print('real values: {}'.format(real));\n",
        "\n",
        "test_acc = accuracy_score(real, preds);\n",
        "test_prec = precision_score(real, preds,average=None);\n",
        "test_rec = recall_score(real, preds,average=None);\n",
        "test_f1 = f1_score(real, preds,average=None);\n",
        "\n",
        "print('test accuracy: {}'.format(test_acc));\n",
        "print('test precision: {}'.format(test_prec));\n",
        "print('test recall: {}'.format(test_rec));\n",
        "print('test f1: {}'.format(test_f1));"
      ],
      "metadata": {
        "id": "wT4y-c8XKy2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = test_DDI_model(model, test_data);"
      ],
      "metadata": {
        "id": "RI_ny8meKwP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load test_accumulated.tsv file\n",
        "avg_test_accuracy = 0;\n",
        "\n",
        "test_data = load_and_process_DDI_test_data('all_data_test_data.txt','test', tokenizer=tokenizer);\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TZWcRPjoKv06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def test_DDI_model(model, data, batch_size=12):\n",
        "    model.load_state_dict(torch.load('bioelectra-base-discriminator-pubmed.pt'));\n",
        "\n",
        "    model.eval();\n",
        "\n",
        "    ds = data;\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        ds,\n",
        "        sampler=SequentialSampler(ds),\n",
        "        batch_size=batch_size,\n",
        "    );\n",
        "\n",
        "    preds_list, real_labels_list = [], [];\n",
        "\n",
        "    for batch_nbr, batch in enumerate(test_dataloader):\n",
        "        b_input_ids = batch[0].to(device);\n",
        "        b_input_mask = batch[1].to(device);\n",
        "        b_labels = batch[2].to(device);\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            );\n",
        "        loss = output.loss;\n",
        "        preds = torch.argmax(output.logits, dim=1).flatten()\n",
        "        logits = preds.detach().cpu().numpy();\n",
        "        label_ids = b_labels.to('cpu').numpy();\n",
        "        \n",
        "\n",
        "        preds_list.append(logits);\n",
        "        real_labels_list.append(label_ids);\n",
        "\n",
        "        print('finished batch {}'.format(batch_nbr));\n",
        "\n",
        "    ret = (\n",
        "        preds_list,\n",
        "        real_labels_list\n",
        "    );\n",
        "    \n",
        "    return ret;"
      ],
      "metadata": {
        "id": "9h-Bq5m1Kpk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display;\n",
        "def load_and_process_DDI_test_data(filepath,set_type, tokenizer, maxlen=512):\n",
        "    \n",
        "    relation_labels=['false', 'mechanism', 'effect', 'advise', 'int']\n",
        "    print( \"Input File Reading\")\n",
        "    fp = open(filepath, 'r')\n",
        "    samples = fp.read().strip().split('\\n\\n')\n",
        "    sent_lengths   = []\t\t#1-d array\n",
        "    sent_contents  = []\t\t#2-d array [[w1,w2,....] ...]\n",
        "    labels    = []\t\t#1-d array\n",
        "    entity1_list   = []\t\t#2-d array [[e1,e1_t] [e1,e1_t]...]\n",
        "    entity2_list   = []\t\t#2-d array [[e1,e1_t] [e1,e1_t]...]\n",
        "    examples = []\n",
        "    i=0\n",
        "    for sample in samples:\n",
        "      guid = \"%s-%s\" % (set_type, i)\n",
        "      sent, entities, relation = sample.strip().split('\\n')\n",
        "\n",
        "      e1, e1_t, e2, e2_t = entities.split('\\t') \n",
        "      sent_contents.append(sent.lower())\n",
        "      label = relation_labels.index(relation) \n",
        "      examples.append(InputExample(guid=guid, text_a=sent.lower(), label=label))\n",
        "      entity1_list.append([e1, e1_t])\n",
        "      entity2_list.append([e2, e2_t])\n",
        "      print(label)\n",
        "      labels.append(label)\n",
        "      i = i+1\n",
        "\n",
        "\n",
        "\n",
        "    input_ids = [];\n",
        "    attention_masks = [];\n",
        "    \n",
        "    for sent in sent_contents:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            sent,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        );\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids']);\n",
        "        attention_masks.append(encoded_dict['attention_mask']);\n",
        "\n",
        "    # convert lists into tensors\n",
        "    input_ids = torch.cat(input_ids, dim=0);\n",
        "    attention_masks = torch.cat(attention_masks, dim=0);\n",
        "    labels_tensor = torch.tensor(labels);\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels_tensor);\n",
        "\n",
        "\n",
        "    return dataset;"
      ],
      "metadata": {
        "id": "JqTqOSuKKmxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_DDI_model(model, data);"
      ],
      "metadata": {
        "id": "Zr1XEGAKKhBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_DDI_model(model, data, optimizer=AdamW, batch_size=12, epochs=3):\n",
        "    max_val_loss = np.float('inf');\n",
        "\n",
        "    train_ds = data[0];\n",
        "    val_ds = data[1];\n",
        "\n",
        "    train_dataloader = DataLoader(\n",
        "        train_ds,\n",
        "        sampler=RandomSampler(train_ds),\n",
        "        batch_size=batch_size\n",
        "    );\n",
        "\n",
        "    val_dataloader = DataLoader(\n",
        "        val_ds,\n",
        "        sampler=SequentialSampler(val_ds),\n",
        "        batch_size=batch_size\n",
        "    );\n",
        "\n",
        "    for e in range(epochs):\n",
        "        train_loss = 0;\n",
        "        train_acc = 0;\n",
        "\n",
        "        model.train();\n",
        "\n",
        "        optim = optimizer(model.parameters(), lr=2e-5, eps=1e-8);\n",
        "\n",
        "        scheduler = get_linear_schedule_with_warmup(\n",
        "            optim,\n",
        "            num_warmup_steps=0,\n",
        "            num_training_steps=len(train_dataloader) * epochs\n",
        "        );\n",
        "\n",
        "        for batch in train_dataloader:\n",
        "            b_input_ids = batch[0].to(device);\n",
        "            b_input_mask = batch[1].to(device);\n",
        "            b_labels = batch[2].to(device);\n",
        "\n",
        "            model.zero_grad();\n",
        "\n",
        "            output = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask,\n",
        "                labels=b_labels\n",
        "            );\n",
        "\n",
        "            loss = output.loss;\n",
        "            preds = torch.argmax(output.logits, dim=1).flatten()\n",
        "            preds = preds.detach().cpu().numpy();\n",
        "            #print(preds)\n",
        "            labels = b_labels.to('cpu').numpy();\n",
        "            #print(labels)\n",
        "            train_loss += loss.item();\n",
        "            train_acc += accuracy(preds, labels);\n",
        "            #print(train_acc)\n",
        "            loss.backward();\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0);\n",
        "\n",
        "            optim.step();\n",
        "\n",
        "            scheduler.step();\n",
        "        \n",
        "        avg_train_loss = train_loss / len(train_dataloader);\n",
        "        avg_train_acc = train_acc / len(train_dataloader);\n",
        "\n",
        "        print('average training loss for epoch: {}'.format(avg_train_loss));\n",
        "        print('average training accuracy for epoch: {}'.format(avg_train_acc));\n",
        "\n",
        "        # validation\n",
        "        val_loss = 0;\n",
        "        val_acc = 0;\n",
        "\n",
        "        model.eval();\n",
        "\n",
        "        for batch in val_dataloader:\n",
        "            b_input_ids = batch[0].to(device);\n",
        "            b_attention_mask = batch[1].to(device);\n",
        "            b_labels = batch[2].to(device);\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(\n",
        "                    b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_attention_mask,\n",
        "                    labels=b_labels\n",
        "                );\n",
        "            \n",
        "            loss = output['loss'];\n",
        "            preds = torch.argmax(output.logits, dim=1).flatten()\n",
        "            preds = preds.detach().cpu().numpy();\n",
        "            labels = b_labels.to('cpu').numpy();\n",
        "\n",
        "            val_loss += loss.item();\n",
        "            val_acc += accuracy(preds, labels);\n",
        "        \n",
        "        avg_val_loss = val_loss / len(val_dataloader);\n",
        "        avg_val_acc = val_acc / len(val_dataloader);\n",
        "\n",
        "        if avg_val_loss < max_val_loss:\n",
        "            max_val_loss = avg_val_loss;\n",
        "            torch.save(model.state_dict(), 'bioelectra-base-discriminator-pubmed.pt');\n",
        "\n",
        "        print('average validation loss for epoch: {}'.format(avg_val_loss));\n",
        "        print('average validation accuracy for epoch: {}'.format(avg_val_acc));"
      ],
      "metadata": {
        "id": "69o_7CueKcZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = load_and_process_DDI_train_data('all_data_train_data.txt','train' ,tokenizer=tokenizer, maxlen=256);\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nKOIZpeiKbPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = ElectraTokenizer.from_pretrained('kamalkraj/bioelectra-base-discriminator-pubmed',do_lower_case=True)\n",
        "\n",
        "model = ElectraForSequenceClassification.from_pretrained(\n",
        "    'kamalkraj/bioelectra-base-discriminator-pubmed',\n",
        "    num_labels=5,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ");\n",
        "\n",
        "device = torch.device('cuda');\n",
        "model.cuda();\n",
        "\n",
        "epochs = 2;"
      ],
      "metadata": {
        "id": "MO43-SFkKTsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_DDI_train_data(filepath,set_type, tokenizer, maxlen=512, train_percentage=0.7):\n",
        "    # load dataset\n",
        "\n",
        "    relation_labels=['false', 'mechanism', 'effect', 'advise', 'int']\n",
        "    print( \"Input File Reading\")\n",
        "    fp = open(filepath, 'r')\n",
        "    samples = fp.read().strip().split('\\n\\n')\n",
        "    sent_lengths   = []\t\t#1-d array\n",
        "    sent_contents  = []\t\t#2-d array [[w1,w2,....] ...]\n",
        "    labels    = []\t\t#1-d array\n",
        "    entity1_list   = []\t\t#2-d array [[e1,e1_t] [e1,e1_t]...]\n",
        "    entity2_list   = []\t\t#2-d array [[e1,e1_t] [e1,e1_t]...]\n",
        "    examples = []\n",
        "    i=0\n",
        "    for sample in samples:\n",
        "      guid = \"%s-%s\" % (set_type, i)\n",
        "      sent, entities, relation = sample.strip().split('\\n')\n",
        "\n",
        "      e1, e1_t, e2, e2_t = entities.split('\\t') \n",
        "      sent_contents.append(sent.lower())\n",
        "      label = relation_labels.index(relation) \n",
        "      examples.append(InputExample(guid=guid, text_a=sent.lower(), label=label))\n",
        "      entity1_list.append([e1, e1_t])\n",
        "      entity2_list.append([e2, e2_t])\n",
        "      print(label)\n",
        "      labels.append(label)\n",
        "      i = i+1\n",
        "\n",
        "\n",
        "\n",
        "    input_ids = [];\n",
        "    attention_masks = [];\n",
        "    \n",
        "    for sent in sent_contents:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            sent,\n",
        "            add_special_tokens=True,\n",
        "            max_length=maxlen,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        );\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids']);\n",
        "        attention_masks.append(encoded_dict['attention_mask']);\n",
        "        \n",
        "\n",
        "    # convert lists into tensors\n",
        "    input_ids = torch.cat(input_ids, dim=0);\n",
        "    attention_masks = torch.cat(attention_masks, dim=0);\n",
        "    labels_tensor = torch.tensor(labels);\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels_tensor);\n",
        "\n",
        "    train_size = int(train_percentage * len(dataset));\n",
        "    val_size = len(dataset) - train_size;\n",
        "\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size]);\n",
        "\n",
        "    return (train_dataset, val_dataset);\n"
      ],
      "metadata": {
        "id": "17NSVjmNKM48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "\n",
        "!pip install transformers\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import numpy as np;\n",
        "import pandas as pd;\n",
        "\n",
        "import torch;\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig;\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler;\n",
        "from transformers import get_linear_schedule_with_warmup;\n",
        "\n",
        "from transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer, BertModel, BertForTokenClassification,\n",
        "                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n",
        "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
        "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer,\n",
        "                                  AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer, AlbertModel,AlbertForMaskedLM,\n",
        "                                  AutoTokenizer, AutoModelForTokenClassification, AutoConfig,\n",
        "                           XLMRobertaTokenizer,XLMRobertaForSequenceClassification,\n",
        "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer,\n",
        "                          ElectraTokenizer,ElectraForSequenceClassification\n",
        "                          )\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score;\n",
        "from transformers import AlbertTokenizer, AlbertForSequenceClassification, AlbertConfig, AdamW, DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import gc\n",
        "    \n",
        "gc.collect()\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import copy\n",
        "import json\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"\n",
        "    A single training/test example for simple sequence classification.\n",
        "    Args:\n",
        "        guid: Unique id for the example.\n",
        "        text_a: string. The untokenized text of the first sequence. For single\n",
        "        sequence tasks, only this sequence must be specified.\n",
        "        label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, label):\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "\n",
        "tokenizer = ElectraTokenizer.from_pretrained('kamalkraj/bioelectra-base-discriminator-pubmed',do_lower_case=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "bGZHsrdTKEBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HMAdOuHJ77a"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/\n",
        "!ls\n"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "def main():\n",
        "\n",
        "  robert_prediction = preds\n",
        "  bert_prediction = preds1\n",
        "  \n",
        "  electra=preds2\n",
        "  final_prediction = majority_voting(robert_prediction,\n",
        "                                           bert_prediction,electra)\n",
        "        # Compute accuracy\n",
        "  print(final_prediction)\n",
        "  print(\"ACCURACY:\", accuracy_score(real, final_prediction))\n",
        "\n",
        "        # Save model\n",
        "\n",
        "\n",
        "\n",
        "  a=f1_score(real, final_prediction, average='macro')\n",
        "  test_prec = precision_score(real, final_prediction,average='macro');\n",
        "  test_rec = recall_score(real, final_prediction,average='macro');\n",
        "  print(a)\n",
        "  print(test_prec)\n",
        "  print(test_rec)\n",
        "  return(final_prediction)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    final_prediction=main()"
      ],
      "metadata": {
        "id": "TL66ZryM_fas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib\n",
        "\n",
        "\n",
        "\n",
        "def majority_voting(robert_prediction, bert_prediction,electra):\n",
        "\n",
        "    final_prediction = list()\n",
        "    for robert,bert,elec in zip(robert_prediction,\n",
        "                                   bert_prediction,electra):\n",
        "        # Keep track of votes per class\n",
        "        false = advise = mechanism = effect = intt = 0\n",
        "\n",
        "        # Loop over all models\n",
        "        predictions = [robert,bert,elec]\n",
        "        for prediction in predictions:\n",
        "            # Voting\n",
        "            if prediction == 0:\n",
        "                false += 1\n",
        "            elif prediction == 1:\n",
        "                advise += 1\n",
        "            elif prediction == 2:\n",
        "                mechanism += 1\n",
        "            elif prediction == 3:\n",
        "                effect += 1\n",
        "            elif prediction == 4:\n",
        "                intt += 1\n",
        "\n",
        "        # Find max vote\n",
        "        count_dict = {'false': false, 'advise': advise, 'mechanism': mechanism, 'effect': effect, 'int': intt}\n",
        "        highest = max(count_dict.values())\n",
        "        max_values = [k for k, v in count_dict.items() if v == highest]\n",
        "        ensemble_prediction = []\n",
        "        for max_value in max_values:\n",
        "            if max_value == 'false':\n",
        "                ensemble_prediction.append('false')\n",
        "            elif max_value == 'advise':\n",
        "                ensemble_prediction.append('advise')\n",
        "            elif max_value == 'mechanism':\n",
        "                ensemble_prediction.append('mechanism')\n",
        "            elif max_value == 'effect':\n",
        "                ensemble_prediction.append('effect')\n",
        "            elif max_value == 'int':\n",
        "                ensemble_prediction.append('int')\n",
        "\n",
        "        predict = ''\n",
        "\n",
        "        predict = ensemble_prediction[0]\n",
        "\n",
        "        # Store max vote\n",
        "        final_prediction.append(predict)\n",
        "    a=[]\n",
        "    for i in range(0,len(final_prediction)):\n",
        "      if final_prediction[i]=='false':\n",
        "        a.append(0)\n",
        "      elif final_prediction[i]=='advise':\n",
        "        a.append(1)\n",
        "      elif final_prediction[i]=='mechanism':\n",
        "        a.append(2)\n",
        "      elif final_prediction[i]=='effect':\n",
        "        a.append(3)\n",
        "      elif final_prediction[i]=='int':\n",
        "        a.append(4)\n",
        "    return np.array(a)"
      ],
      "metadata": {
        "id": "ZQDz4qvz_Zxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds2 = np.concatenate(ret2[0]);\n",
        "real2 = np.concatenate(ret2[1]);\n",
        "\n",
        "print('test predictions: {}'.format(preds2));\n",
        "print('real values: {}'.format(real2));\n",
        "\n",
        "test_acc = accuracy_score(real2, preds2);\n",
        "test_prec = precision_score(real2, preds2,average=None);\n",
        "test_rec = recall_score(real2, preds2,average=None);\n",
        "test_f1 = f1_score(real2, preds2,average=None);\n",
        "\n",
        "print('test accuracy: {}'.format(test_acc));\n",
        "print('test precision: {}'.format(test_prec));\n",
        "print('test recall: {}'.format(test_rec));\n",
        "print('test f1: {}'.format(test_f1));"
      ],
      "metadata": {
        "id": "msEJdS4O_Tx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds1 = np.concatenate(ret1[0]);\n",
        "real1 = np.concatenate(ret1[1]);\n",
        "\n",
        "print('test predictions: {}'.format(preds1));\n",
        "print('real values: {}'.format(real1));\n",
        "\n",
        "test_acc = accuracy_score(real1, preds1);\n",
        "test_prec = precision_score(real1, preds1,average=None);\n",
        "test_rec = recall_score(real1, preds1,average=None);\n",
        "test_f1 = f1_score(real1, preds1,average=None);\n",
        "\n",
        "print('test accuracy: {}'.format(test_acc));\n",
        "print('test precision: {}'.format(test_prec));\n",
        "print('test recall: {}'.format(test_rec));\n",
        "print('test f1: {}'.format(test_f1));"
      ],
      "metadata": {
        "id": "7cHu3RBw_NIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.concatenate(ret[0]);\n",
        "real = np.concatenate(ret[1]);\n",
        "\n",
        "print('test predictions: {}'.format(preds));\n",
        "print('real values: {}'.format(real));\n",
        "\n",
        "test_acc = accuracy_score(real, preds);\n",
        "test_prec = precision_score(real, preds,average=None);\n",
        "test_rec = recall_score(real, preds,average=None);\n",
        "test_f1 = f1_score(real, preds,average=None);\n",
        "\n",
        "print('test accuracy: {}'.format(test_acc));\n",
        "print('test precision: {}'.format(test_prec));\n",
        "print('test recall: {}'.format(test_rec));\n",
        "print('test f1: {}'.format(test_f1));"
      ],
      "metadata": {
        "id": "4m7UQgFm07ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = test_DDI_model(model, test_data);\n",
        "ret1 = test_DDI_model1(model1, test_dataa);\n",
        "ret2 = test_DDI_model3(model2, test_dataaa);\n"
      ],
      "metadata": {
        "id": "tZu_cejr05Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# load test_accumulated.tsv file\n",
        "avg_test_accuracy = 0;\n",
        "\n",
        "test_data = load_and_process_DDI_test_data('all_data_test_data.txt','test', tokenizer=tokenizer);\n",
        "test_dataa = load_and_process_DDI_test_data('all_data_test_data.txt','test', tokenizer=tokenizer1);\n",
        "test_dataaa = load_and_process_DDI_test_data('all_data_test_data.txt','test', tokenizer=tokenizer2);\n"
      ],
      "metadata": {
        "id": "EE79EY8-0289"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_DDI_model3(model, data, batch_size=12):\n",
        "    model.load_state_dict(torch.load('bioelectra-base-discriminator-pubmed.pt'));\n",
        "\n",
        "    model.eval();\n",
        "\n",
        "    ds = data;\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        ds,\n",
        "        sampler=SequentialSampler(ds),\n",
        "        batch_size=batch_size,\n",
        "    );\n",
        "\n",
        "    preds_list, real_labels_list = [], [];\n",
        "\n",
        "    for batch_nbr, batch in enumerate(test_dataloader):\n",
        "        b_input_ids = batch[0].to(device2);\n",
        "        b_input_mask = batch[1].to(device2);\n",
        "        b_labels = batch[2].to(device2);\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            );\n",
        "        loss = output.loss;\n",
        "        preds = torch.argmax(output.logits, dim=1).flatten()\n",
        "        logits = preds.detach().cpu().numpy();\n",
        "        label_ids = b_labels.to('cpu').numpy();\n",
        "        \n",
        "\n",
        "        preds_list.append(logits);\n",
        "        real_labels_list.append(label_ids);\n",
        "\n",
        "        print('finished batch {}'.format(batch_nbr));\n",
        "\n",
        "    ret = (\n",
        "        preds_list,\n",
        "        real_labels_list\n",
        "    );\n",
        "    \n",
        "    return ret;"
      ],
      "metadata": {
        "id": "EoyfaHSn0z9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_DDI_model1(model, data, batch_size=12):\n",
        "    model.load_state_dict(torch.load('biobert.pt'));\n",
        "\n",
        "    model.eval();\n",
        "\n",
        "    ds = data;\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        ds,\n",
        "        sampler=SequentialSampler(ds),\n",
        "        batch_size=batch_size,\n",
        "    );\n",
        "\n",
        "    preds_list, real_labels_list = [], [];\n",
        "\n",
        "    for batch_nbr, batch in enumerate(test_dataloader):\n",
        "        b_input_ids = batch[0].to(device1);\n",
        "        b_input_mask = batch[1].to(device1);\n",
        "        b_labels = batch[2].to(device1);\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            );\n",
        "        loss = output.loss;\n",
        "        preds = torch.argmax(output.logits, dim=1).flatten()\n",
        "        logits = preds.detach().cpu().numpy();\n",
        "        label_ids = b_labels.to('cpu').numpy();\n",
        "        \n",
        "\n",
        "        preds_list.append(logits);\n",
        "        real_labels_list.append(label_ids);\n",
        "\n",
        "        print('finished batch {}'.format(batch_nbr));\n",
        "\n",
        "    ret = (\n",
        "        preds_list,\n",
        "        real_labels_list\n",
        "    );\n",
        "    \n",
        "    return ret;"
      ],
      "metadata": {
        "id": "mvf8rKSI0w8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_DDI_model(model, data, batch_size=12):\n",
        "    model.load_state_dict(torch.load('biomed_roberta_base.pt'));\n",
        "\n",
        "    model.eval();\n",
        "\n",
        "    ds = data;\n",
        "\n",
        "    test_dataloader = DataLoader(\n",
        "        ds,\n",
        "        sampler=SequentialSampler(ds),\n",
        "        batch_size=batch_size,\n",
        "    );\n",
        "\n",
        "    preds_list, real_labels_list = [], [];\n",
        "\n",
        "    for batch_nbr, batch in enumerate(test_dataloader):\n",
        "        b_input_ids = batch[0].to(device);\n",
        "        b_input_mask = batch[1].to(device);\n",
        "        b_labels = batch[2].to(device);\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(\n",
        "                b_input_ids,\n",
        "                token_type_ids=None,\n",
        "                attention_mask=b_input_mask\n",
        "            );\n",
        "        loss = output.loss;\n",
        "        preds = torch.argmax(output.logits, dim=1).flatten()\n",
        "        logits = preds.detach().cpu().numpy();\n",
        "        label_ids = b_labels.to('cpu').numpy();\n",
        "        \n",
        "\n",
        "        preds_list.append(logits);\n",
        "        real_labels_list.append(label_ids);\n",
        "\n",
        "        print('finished batch {}'.format(batch_nbr));\n",
        "\n",
        "    ret = (\n",
        "        preds_list,\n",
        "        real_labels_list\n",
        "    );\n",
        "    \n",
        "    return ret;"
      ],
      "metadata": {
        "id": "1aDm6Ak70tU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display;\n",
        "def load_and_process_DDI_test_data(filepath,set_type, tokenizer, maxlen=512):\n",
        "    \n",
        "    relation_labels=['false', 'mechanism', 'effect', 'advise', 'int']\n",
        "    print( \"Input File Reading\")\n",
        "    fp = open(filepath, 'r')\n",
        "    samples = fp.read().strip().split('\\n\\n')\n",
        "    sent_lengths   = []\t\t#1-d array\n",
        "    sent_contents  = []\t\t#2-d array [[w1,w2,....] ...]\n",
        "    labels    = []\t\t#1-d array\n",
        "    entity1_list   = []\t\t#2-d array [[e1,e1_t] [e1,e1_t]...]\n",
        "    entity2_list   = []\t\t#2-d array [[e1,e1_t] [e1,e1_t]...]\n",
        "    examples = []\n",
        "    i=0\n",
        "    for sample in samples:\n",
        "      guid = \"%s-%s\" % (set_type, i)\n",
        "      sent, entities, relation = sample.strip().split('\\n')\n",
        "\n",
        "      e1, e1_t, e2, e2_t = entities.split('\\t') \n",
        "      sent_contents.append(sent.lower())\n",
        "      label = relation_labels.index(relation) \n",
        "      examples.append(InputExample(guid=guid, text_a=sent.lower(), label=label))\n",
        "      entity1_list.append([e1, e1_t])\n",
        "      entity2_list.append([e2, e2_t])\n",
        "      print(label)\n",
        "      labels.append(label)\n",
        "      i = i+1\n",
        "\n",
        "\n",
        "\n",
        "    input_ids = [];\n",
        "    attention_masks = [];\n",
        "    \n",
        "    for sent in sent_contents:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            sent,\n",
        "            add_special_tokens=True,\n",
        "            max_length=512,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        );\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids']);\n",
        "        attention_masks.append(encoded_dict['attention_mask']);\n",
        "\n",
        "    # convert lists into tensors\n",
        "    input_ids = torch.cat(input_ids, dim=0);\n",
        "    attention_masks = torch.cat(attention_masks, dim=0);\n",
        "    labels_tensor = torch.tensor(labels);\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels_tensor);\n",
        "\n",
        "\n",
        "    return dataset;"
      ],
      "metadata": {
        "id": "Odk660ic0p9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = load_and_process_DDI_train_data('all_data_train_data.txt','train' ,tokenizer=tokenizer, maxlen=128);\n",
        "\n",
        "dataa = load_and_process_DDI_train_data('all_data_train_data.txt','train' ,tokenizer=tokenizer1, maxlen=128);\n",
        "\n",
        "dataaa = load_and_process_DDI_train_data('all_data_train_data.txt','train' ,tokenizer=tokenizer2, maxlen=256);\n",
        "\n"
      ],
      "metadata": {
        "id": "TDrvef_40nZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer2 = ElectraTokenizer.from_pretrained('kamalkraj/bioelectra-base-discriminator-pubmed',do_lower_case=True)\n",
        "model2 = ElectraForSequenceClassification.from_pretrained(\n",
        "    'kamalkraj/bioelectra-base-discriminator-pubmed',\n",
        "    num_labels=5,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ");\n",
        "\n",
        "device2 = torch.device('cuda');\n",
        "model2.cuda();\n",
        "\n",
        "epochs = 2;"
      ],
      "metadata": {
        "id": "QwsOOJsx0k_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer1 = BertTokenizer.from_pretrained('monologg/biobert_v1.1_pubmed');\n",
        "\n",
        "model1 = BertForSequenceClassification.from_pretrained(\n",
        "    'monologg/biobert_v1.1_pubmed',\n",
        "    num_labels=5,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ");\n",
        "\n",
        "device1 = torch.device('cuda');\n",
        "model1.cuda();\n",
        "\n",
        "epochs = 2;"
      ],
      "metadata": {
        "id": "YbyX48pf0iYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#tokenizer = RobertaTokenizer.from_pretrained('simonlevine/bioclinical-roberta-long');\n",
        "tokenizer = RobertaTokenizer.from_pretrained('simonlevine/biomed_roberta_base-4096')\n",
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    'simonlevine/biomed_roberta_base-4096',\n",
        "    num_labels=5,\n",
        "    output_attentions=False,\n",
        "    output_hidden_states=False\n",
        ");\n",
        "\n",
        "device = torch.device('cuda');\n",
        "model.cuda();\n",
        "\n",
        "epochs = 2;"
      ],
      "metadata": {
        "id": "-MU1ik1M0e91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_process_DDI_train_data(filepath,set_type, tokenizer, maxlen=512, train_percentage=0.7):\n",
        "    # load dataset\n",
        "\n",
        "    relation_labels=['false', 'mechanism', 'effect', 'advise', 'int']\n",
        "    print( \"Input File Reading\")\n",
        "    fp = open(filepath, 'r')\n",
        "    samples = fp.read().strip().split('\\n\\n')\n",
        "    sent_lengths   = []\t\t#1-d array\n",
        "    sent_contents  = []\t\t#2-d array [[w1,w2,....] ...]\n",
        "    labels    = []\t\t#1-d array\n",
        "    entity1_list   = []\t\t#2-d array [[e1,e1_t] [e1,e1_t]...]\n",
        "    entity2_list   = []\t\t#2-d array [[e1,e1_t] [e1,e1_t]...]\n",
        "    examples = []\n",
        "    i=0\n",
        "    for sample in samples:\n",
        "      guid = \"%s-%s\" % (set_type, i)\n",
        "      sent, entities, relation = sample.strip().split('\\n')\n",
        "\n",
        "      e1, e1_t, e2, e2_t = entities.split('\\t') \n",
        "      sent_contents.append(sent.lower())\n",
        "      label = relation_labels.index(relation) \n",
        "      examples.append(InputExample(guid=guid, text_a=sent.lower(), label=label))\n",
        "      entity1_list.append([e1, e1_t])\n",
        "      entity2_list.append([e2, e2_t])\n",
        "      print(label)\n",
        "      labels.append(label)\n",
        "      i = i+1\n",
        "\n",
        "\n",
        "\n",
        "    input_ids = [];\n",
        "    attention_masks = [];\n",
        "    \n",
        "    for sent in sent_contents:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "            sent,\n",
        "            add_special_tokens=True,\n",
        "            max_length=maxlen,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        );\n",
        "\n",
        "        input_ids.append(encoded_dict['input_ids']);\n",
        "        attention_masks.append(encoded_dict['attention_mask']);\n",
        "        \n",
        "\n",
        "    # convert lists into tensors\n",
        "    input_ids = torch.cat(input_ids, dim=0);\n",
        "    attention_masks = torch.cat(attention_masks, dim=0);\n",
        "    labels_tensor = torch.tensor(labels);\n",
        "\n",
        "    dataset = TensorDataset(input_ids, attention_masks, labels_tensor);\n",
        "\n",
        "    train_size = int(train_percentage * len(dataset));\n",
        "    val_size = len(dataset) - train_size;\n",
        "\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size]);\n",
        "\n",
        "    return (train_dataset, val_dataset);\n"
      ],
      "metadata": {
        "id": "q9n4ebSq0bsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n",
        "\n",
        "!pip install transformers\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "import numpy as np;\n",
        "import pandas as pd;\n",
        "\n",
        "import torch;\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig;\n",
        "from torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler;\n",
        "from transformers import get_linear_schedule_with_warmup;\n",
        "\n",
        "from transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer, BertModel, BertForTokenClassification,\n",
        "                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n",
        "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
        "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer,\n",
        "                                  AlbertConfig, AlbertForSequenceClassification, AlbertTokenizer, AlbertModel,AlbertForMaskedLM,\n",
        "                                  AutoTokenizer, AutoModelForTokenClassification, AutoConfig,\n",
        "                           XLMRobertaTokenizer,XLMRobertaForSequenceClassification,\n",
        "                          RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer,\n",
        "                          ElectraTokenizer,ElectraForSequenceClassification\n",
        "                          )\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score;\n",
        "from transformers import AlbertTokenizer, AlbertForSequenceClassification, AlbertConfig, AdamW, DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
        "\n",
        "\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import gc\n",
        "    \n",
        "gc.collect()\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import copy\n",
        "import json\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class InputExample(object):\n",
        "    \"\"\"\n",
        "    A single training/test example for simple sequence classification.\n",
        "    Args:\n",
        "        guid: Unique id for the example.\n",
        "        text_a: string. The untokenized text of the first sequence. For single\n",
        "        sequence tasks, only this sequence must be specified.\n",
        "        label: (Optional) string. The label of the example. This should be\n",
        "        specified for train and dev examples, but not for test examples.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, label):\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.label = label\n",
        "\n",
        "    def __repr__(self):\n",
        "        return str(self.to_json_string())\n",
        "\n",
        "    def to_dict(self):\n",
        "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
        "        output = copy.deepcopy(self.__dict__)\n",
        "        return output\n",
        "\n",
        "    def to_json_string(self):\n",
        "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
        "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
        "\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "\n",
        "#tokenizer = RobertaTokenizer.from_pretrained('simonlevine/bioclinical-roberta-long')\n",
        "tokenizer = RobertaTokenizer.from_pretrained('simonlevine/biomed_roberta_base-4096')\n",
        "\n",
        "tokenizer1 = BertTokenizer.from_pretrained('monologg/biobert_v1.1_pubmed')\n",
        "\n",
        "\n",
        "tokenizer2 = ElectraTokenizer.from_pretrained('kamalkraj/bioelectra-base-discriminator-pubmed',do_lower_case=True)\n"
      ],
      "metadata": {
        "id": "5Ad4fzPe0Xoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEarI9cp0KVI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/\n",
        "!ls\n"
      ]
    }
  ]
}